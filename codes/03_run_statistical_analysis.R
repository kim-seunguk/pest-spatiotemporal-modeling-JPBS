# -------------------------------------------------------------------------- #
# SCRIPT 3: Final Statistical Analysis and Table Generation
# -------------------------------------------------------------------------- #
#
# Author: Seunguk Kim
# Contact: adrenaline@snu.ac.kr
# Last Modified: 2025-10-21
#
# Description:
# This script performs all supplementary statistical analyses reported
# in the manuscript's Results section (e.g., Mann-Whitney U tests,
# Spearman's correlations, uncertainty driver analysis) and generates
# the final data for Table 3.
#
# Associated Manuscript:
# Bang, S., Kim, S., et al. "From Pest Traps to Management Maps..."
#
# Usage Notes:
# This is the FINAL script. It must be run AFTER the main
# '02_run_xgboost_pipeline.R' has successfully completed.
#
# -------------------------------------------------------------------------- #

# The analyses include:
# 1. Primary descriptive and comparative statistics (Mann-Whitney U, Spearman's rho)
#    for the manuscript's "Field observations" section.
# 2. Generation of a detailed comparison table (for Table 3) for
#    observed vs. predicted values.
# 3. An exploratory analysis of the drivers of prediction uncertainty
#    (for Results 3.5).
# 4. Generation of appendix scatter plots for uncertainty drivers.
#

#### 0. Setup ####
print("--- 0. Setup ---")
print(paste("Pipeline started at:", Sys.time()))

#---- 0.1. Load Libraries ----
suppressPackageStartupMessages({
  library(here)
  library(tidyverse)
  library(xgboost)   # To load/use saved models
  library(terra)     # For raster analysis
  library(sf)        # For distance calculations
  library(patchwork) # For combining appendix plots
})

#---- 0.2. Define File Paths ----
dir_output_base <- here("output")
dir_data_prep <- file.path(dir_output_base, "prepared_data")
dir_models <- file.path(dir_output_base, "models")
dir_evaluation <- file.path(dir_output_base, "evaluation")
dir_predictions <- file.path(dir_output_base, "predictions")

dir_raw_data <- here("data")
dir_raw_predictors <- file.path(dir_raw_data, "predictors", "1km")
dir_raw_occurrence <- file.path(dir_raw_data, "occurrence")

#---- 0.3. Package Version Management (renv) ----
# This project uses 'renv' to ensure reproducibility.
# If you are running this for the first time, run:
# > renv::restore()


#### 1. Data Loading ####
#
# Description:
# This section loads all necessary data artifacts generated by the
# main pipeline (03) and the raw data from the phenology script (01).
#

print("--- 1. Loading Data from Main Pipeline ---")

#---- 1.1. Load Raw Observation Data ----
# This is used for the initial descriptive stats (Table 2 context)
# NOTE: Ensure all input CSV files (occurrence*.csv, phenology_metrics_clean.csv)
# are saved with UTF-8 encoding.
path_occ_2022 <- file.path(dir_raw_occurrence, "occurrence2022.csv")
path_occ_2023 <- file.path(dir_raw_occurrence, "occurrence2023.csv")
path_phenology <-
  file.path(dir_output_base,
            "phenology",
            "data",
            "phenology_metrics_clean.csv")

if (!file.exists(path_occ_2022) ||
    !file.exists(path_occ_2023) || !file.exists(path_phenology)) {
  stop(
    "Raw occurrence or phenology CSV files not found. Please run '01_process_phenology_data.R' first."
  )
}

df_abundance_raw <- bind_rows(
  read.csv(path_occ_2022) %>%
    dplyr::select(Area, Region, trap_no, lon, lat, Total_Abundance = total) %>%
    mutate(Year = 2022),
  read.csv(path_occ_2023) %>%
    dplyr::select(Area, Region, trap_no, lon, lat, Total_Abundance = total) %>%
    mutate(Year = 2023)
)
df_phenology_raw <- read.csv(path_phenology)

df_analysis_full <- df_abundance_raw %>%
  mutate(
    point_id = paste(Year, Area, Region, trap_no, lon, lat, sep = "_"),
    location_id = paste(Area, Region, trap_no, lon, lat, sep = "_")
  ) %>%
  left_join(
    df_phenology_raw %>%
      mutate(point_id = paste(Year, Area, Region, trap_no, lon, lat, sep = "_")) %>%
      dplyr::select(
        point_id,
        Onset_Week = First_Occurrence_5pct,
        Peak_Week = Peak_Occurrence_Mode
      ),
    by = "point_id"
  )

df_traps_sf <- df_abundance_raw %>%
  distinct(lon, lat) %>%
  st_as_sf(coords = c("lon", "lat"), crs = 4326)

#---- 1.2. Load Modeling and Prediction Data from Pipeline ----
# Load the final dataset used for modeling
master_data_path <- file.path(dir_data_prep, "master_data.rds")
if (!file.exists(master_data_path)) {
  stop(
    "Master data file (master_data.rds) not found. Please run '03_run_xgboost_pipeline.R' first."
  )
}
master_data <- readRDS(master_data_path)

# Load prediction and uncertainty rasters
uncertainty_files <-
  list.files(dir_predictions,
             pattern = "^uncertainty_width_.*\\.tif$",
             full.names = TRUE)
prediction_files <-
  list.files(dir_predictions,
             pattern = "^prediction_mean_.*\\.tif$",
             full.names = TRUE)

if (length(uncertainty_files) == 0 || length(prediction_files) == 0) {
  stop(
    "Prediction/Uncertainty rasters not found. Please run '03_run_xgboost_pipeline.R' first."
  )
}

uncertainty_rasters <- map(uncertainty_files, terra::rast)
names(uncertainty_rasters) <-
  str_remove_all(basename(uncertainty_files), ".tif|uncertainty_width_")
prediction_rasters <- map(prediction_files, terra::rast)
names(prediction_rasters) <-
  str_remove_all(basename(prediction_files), ".tif|prediction_mean_")

# Load SHAP importance rankings
shap_files <-
  list.files(dir_evaluation,
             pattern = "^shap_importance_.*\\.rds$",
             full.names = TRUE)
if (length(shap_files) == 0) {
  stop(
    "SHAP importance files (.rds) not found. Please run '03_run_xgboost_pipeline.R' first."
  )
}
shap_importance_list <- map(shap_files, readRDS)
names(shap_importance_list) <-
  str_remove_all(basename(shap_files), ".rds|shap_importance_")


#### 2. Primary Statistical Analyses ####
#
# Description:
# Performs Mann-Whitney U and Spearman's rho tests on the full observational
# dataset, corresponding to Results section 3.1.
#

print("\n--- 2. Performing Primary Statistical Analyses (for Results 3.1) ---")

response_vars <- c("Total_Abundance", "Onset_Week", "Peak_Week")
df_analysis_full$Year <- as.factor(df_analysis_full$Year)
results_list <- list()

for (metric in response_vars) {
  cat(paste("\n\n===== Analyzing Metric:", metric, "=====\n"))
  
  #-- Mann-Whitney U Test (Inter-annual difference) --
  cat("-> Performing Mann-Whitney U Test...\n")
  data_for_mw_test <-
    df_analysis_full %>% dplyr::select(Year,!!sym(metric)) %>% drop_na()
  formula_mw <- as.formula(paste(metric, "~ Year"))
  mw_test <- wilcox.test(formula_mw, data = data_for_mw_test)
  print(mw_test)
  
  #-- Spearman's Rank Correlation (Inter-annual spatial consistency) --
  cat("-> Performing Spearman's Correlation...\n")
  data_for_spearman_test <- df_analysis_full %>%
    dplyr::select(location_id, Year,!!sym(metric)) %>%
    pivot_wider(
      names_from = Year,
      values_from = !!sym(metric),
      names_prefix = paste0(metric, "_")
    ) %>%
    drop_na()
  
  if (nrow(data_for_spearman_test) > 2) {
    spearman_test <- cor.test(
      data_for_spearman_test[[paste0(metric, "_2022")]],
      data_for_spearman_test[[paste0(metric, "_2023")]],
      method = "spearman",
      exact = FALSE
    )
    print(spearman_test)
    rho_value <- spearman_test$estimate
    rho_p_value <- spearman_test$p.value
  } else {
    rho_value <- NA
    rho_p_value <- NA
  }
  
  results_list[[metric]] <- tibble(
    Metric = metric,
    Mann_Whitney_W = mw_test$statistic,
    Mann_Whitney_p_value = mw_test$p.value,
    Spearman_rho = rho_value,
    Spearman_p_value = rho_p_value,
    N_paired_sites_for_rho = nrow(data_for_spearman_test)
  )
}
results_summary <- bind_rows(results_list)
print("--- Final Primary Statistical Test Summary ---")
print(results_summary, digits = 4)


#### 3. Observed vs. Predicted Comparison Table ####
#
# Description:
# Generates predictions on the final modeling dataset and creates a detailed
# table comparing observed vs. predicted statistics (for Table 3).
#

print("\n--- 3. Generating Observed vs. Predicted Comparison Table (for Table 3) ---")

#---- 3.1. Prepare Data for Comparison ----
# Start with the final modeling dataset for a true apples-to-apples comparison.
df_comparison <- master_data

# Back-transform the observed abundance from log scale to the original count scale.
df_comparison <- df_comparison %>%
  rename(Total_Abundance_log = Total_Abundance) %>%
  mutate(Total_Abundance = expm1(Total_Abundance_log)) # expm1 reverses log1p

#---- 3.2. Generate Predictions ----
# Loop through each response variable to load its model and generate predictions.
for (metric in response_vars) {
  cat(paste("\n-> Generating predictions for:", metric, "\n"))
  
  # Load model and features
  model_path <-
    file.path(dir_models, paste0("definitive_model_", metric, ".rds"))
  features_path <-
    file.path(dir_models, paste0("definitive_features_", metric, ".rds"))
  if (!file.exists(model_path) || !file.exists(features_path)) {
    warning(paste("Model/feature file for", metric, "not found. Skipping."))
    next
  }
  model <- readRDS(model_path)
  features <- readRDS(features_path)
  
  # Subset data for the specific metric (removes NAs for phenology)
  prediction_data_subset <- if (metric == "Total_Abundance") {
    df_comparison
  } else {
    df_comparison %>% filter(!is.na(.data[[metric]]))
  }
  
  # Select only the predictor columns in the correct order
  predictors_matrix <- prediction_data_subset %>%
    dplyr::select(all_of(features)) %>%
    data.matrix()
  
  # Generate predictions
  predictions <- predict(model, predictors_matrix)
  
  # Back-transform abundance predictions
  if (metric == "Total_Abundance") {
    predictions <- expm1(predictions) # Reverses log1p
  }
  
  # Add predictions to the subset data
  pred_col_name <- paste0("Predicted_", metric)
  prediction_data_subset <- prediction_data_subset %>%
    mutate(!!pred_col_name := predictions)
  
  # Join the predictions back to the main comparison dataframe
  df_comparison <- df_comparison %>%
    left_join(
      prediction_data_subset %>% dplyr::select(Year, lon, lat,!!pred_col_name),
      by = c("Year", "lon", "lat")
    )
}

#---- 3.3. Calculate and Format Statistics ----
# Calculate all desired stats for both observed and predicted values.
table3_long_format <- df_comparison %>%
  dplyr::select(
    Year,
    Observed_Total_Abundance = Total_Abundance,
    Predicted_Total_Abundance,
    Observed_Onset_Week = Onset_Week,
    Predicted_Onset_Week,
    Observed_Peak_Week = Peak_Week,
    Predicted_Peak_Week
  ) %>%
  pivot_longer(
    cols = -Year,
    names_to = c("Source", "Metric"),
    names_pattern = "([a-zA-Z]+)_(.*)",
    values_to = "Value"
  ) %>%
  group_by(Metric, Year, Source) %>%
  summarise(
    N = sum(!is.na(Value)),
    Mean = mean(Value, na.rm = TRUE),
    SD = sd(Value, na.rm = TRUE),
    Min = min(Value, na.rm = TRUE),
    Median = median(Value, na.rm = TRUE),
    Max = max(Value, na.rm = TRUE),
    .groups = 'drop'
  )

#---- 3.4. Reshape for CSV Export (Matches Table 3 structure) ----
table3_for_csv <- table3_long_format %>%
  pivot_wider(
    names_from = Source,
    values_from = c(N, Mean, SD, Min, Median, Max)
  ) %>%
  dplyr::select(
    Metric,
    Year,
    N = N_Observed,
    # Re-order columns to match Observed/Predicted pairs
    Mean_Observed,
    Mean_Predicted,
    SD_Observed,
    SD_Predicted,
    Min_Observed,
    Min_Predicted,
    Median_Observed,
    Median_Predicted,
    Max_Observed,
    Max_Predicted
  ) %>%
  arrange(Metric, Year)

#---- 3.5. Save and Display Comparison Table ----
output_csv_path <-
  file.path(dir_evaluation, "comparison_table_for_manuscript.csv")
write.csv(table3_for_csv, output_csv_path, row.names = FALSE, na = "")
print(paste("--- Comparison table saved to:", output_csv_path, "---"))
print(table3_for_csv, n = 50, digits = 2)


#### 4. Uncertainty Driver Analysis ####
#
# Description:
# Investigates the drivers of prediction uncertainty using the raster outputs,
# corresponding to Results section 3.5.
#

print("\n--- 4. Analyzing Drivers of Uncertainty (for Results 3.5) ---")

# Create a map to find the correct raster file for top SHAP predictors
predictor_files_all <-
  list.files(dir_raw_predictors, pattern = "\\.tif$", full.names = FALSE)
predictor_basenames <-
  tools::file_path_sans_ext(predictor_files_all)
predictor_name_map <-
  setNames(predictor_files_all, predictor_basenames)

# Manually add mappings for dynamic/renamed variables
predictor_name_map["LST_Day"] <-
  "LST_Day_2023.tif" # Use 2023 as example year
predictor_name_map["LST_Night"] <- "LST_Night_2023.tif"
predictor_name_map["Annual Mean Temp"] <- "bio1.tif"
predictor_name_map["Temp Seasonality"] <- "bio4.tif"
predictor_name_map["Mean Temp of Coldest Quarter"] <- "bio11.tif"
predictor_name_map["Precip Seasonality"] <- "bio15.tif"
predictor_name_map["Host Abundance (Pinus thunbergii)"] <- "Ab_PT.tif"
predictor_name_map["Min Temp of Coldest Month"] <- "bio6.tif"

# Initialize lists to store results for the appendix plot
sampled_data_list <- list()
correlation_results_list <- list()

for (response_var in response_vars) {
  cat(paste("\n\n===== Analyzing Uncertainty for:", response_var, "=====\n"))
  
  year_suffix <- "_2023" # Using 2023 as the example year
  pred_rast <-
    prediction_rasters[[paste0(response_var, year_suffix)]]
  uncert_rast <-
    uncertainty_rasters[[paste0(response_var, year_suffix)]]
  
  if (is.null(pred_rast) || is.null(uncert_rast)) {
    warning(paste("Skipping", response_var, "due to missing raster files."))
    next
  }
  
  #-- Analysis 1: Prediction Magnitude vs. Uncertainty --
  cat("-> Analyzing Prediction vs. Uncertainty...\n")
  analysis_stack_mag <- c(pred_rast, uncert_rast)
  names(analysis_stack_mag) <- c("Prediction", "Uncertainty")
  set.seed(123)
  sampled_points_mag <-
    spatSample(analysis_stack_mag, size = 10000, na.rm = TRUE)
  correlation_mag <-
    cor.test(sampled_points_mag$Prediction,
             sampled_points_mag$Uncertainty,
             method = "spearman")
  print(correlation_mag)
  
  # Store for appendix plot
  sampled_data_list[[response_var]][['mag']] <- sampled_points_mag
  correlation_results_list[[response_var]][['mag']] <- correlation_mag
  
  #-- Analysis 2: Data Density vs. Uncertainty --
  cat("-> Analyzing Data Density vs. Uncertainty...\n")
  df_traps_proj <-
    st_transform(df_traps_sf, crs = terra::crs(uncert_rast))
  dist_raster <- terra::distance(uncert_rast, terra::vect(df_traps_proj))
  analysis_stack_dist <- c(dist_raster, uncert_rast)
  names(analysis_stack_dist) <- c("Distance", "Uncertainty")
  set.seed(456)
  sampled_points_dist <-
    spatSample(analysis_stack_dist, size = 10000, na.rm = TRUE)
  correlation_dist <-
    cor.test(sampled_points_dist$Distance,
             sampled_points_dist$Uncertainty,
             method = "spearman")
  print(correlation_dist)
  
  # Store for appendix plot
  sampled_data_list[[response_var]][['dist']] <- sampled_points_dist
  correlation_results_list[[response_var]][['dist']] <-
    correlation_dist
  
  #-- Analysis 3: Top Environment Predictor vs. Uncertainty --
  cat("-> Analyzing Top Environment Predictor vs. Uncertainty...\n")
  top_predictor_name <-
    shap_importance_list[[response_var]] %>% dplyr::slice(1) %>% pull(Feature)
  top_predictor_filename <- predictor_name_map[top_predictor_name]
  
  if (is.na(top_predictor_filename)) {
    warning(paste(
      "Could not find a raster file for top predictor:",
      top_predictor_name
    ))
    next
  }
  top_predictor_path <-
    file.path(dir_raw_predictors, top_predictor_filename)
  if (!file.exists(top_predictor_path)) {
    warning(paste("Raster file not found at path:", top_predictor_path))
    next
  }
  env_rast <- terra::rast(top_predictor_path)
  
  analysis_stack_env <- c(env_rast, uncert_rast)
  names(analysis_stack_env) <- c("Environment", "Uncertainty")
  set.seed(789)
  sampled_points_env <-
    spatSample(analysis_stack_env, size = 10000, na.rm = TRUE)
  correlation_env <-
    cor.test(sampled_points_env$Environment,
             sampled_points_env$Uncertainty,
             method = "spearman")
  cat(paste("   - Correlation with", top_predictor_name, ":\n"))
  print(correlation_env)
  
  # Store for appendix plot
  sampled_data_list[[response_var]][['env']] <- sampled_points_env
  correlation_results_list[[response_var]][['env']] <- correlation_env
}


#### 5. Appendix Plot Generation (Scatter Plots) ####
#
# Description:
# This section creates a multi-panel scatter plot figure for the appendix.
# It visualizes the relationships analyzed in Section 4.
#

print("\n--- 5. Generating Appendix Scatter Plots for Uncertainty ---")

#---- 5.1. Create a Plotting Function ----
# This function creates a standardized scatter plot to avoid repeating code.
create_scatter_plot <-
  function(data,
           x_var,
           y_var,
           title,
           x_lab,
           y_lab,
           stats_result) {
    # Extract rho and p-value for annotation
    rho <- round(stats_result$estimate, 2)
    p_value_text <- if (stats_result$p.value < 0.001) {
      "P < 0.001"
    } else {
      paste("P =", round(stats_result$p.value, 3))
    }
    
    annotation_text <-
      paste0("Spearman's ρ = ", rho, "\n", p_value_text)
    
    ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]])) +
      geom_point(alpha = 0.2, size = 0.5) +
      geom_smooth(
        method = "loess",
        se = FALSE,
        color = "blue",
        linewidth = 0.8
      ) +
      labs(title = title,
           x = x_lab,
           y = y_lab) +
      annotate(
        "text",
        x = Inf,
        y = Inf,
        label = annotation_text,
        hjust = 1.1,
        vjust = 1.5,
        size = 3,
        fontface = "italic"
      ) +
      theme_bw(base_size = 10) +
      theme(plot.title = element_text(hjust = 0.5, size = 10))
  }


#---- 5.2. Generate All Individual Plots ----
plot_list <- list()

#-- Total Abundance Plots --
plot_list[["p_ab_mag"]] <- create_scatter_plot(
  data = sampled_data_list$Total_Abundance$mag,
  x_var = "Prediction",
  y_var = "Uncertainty",
  title = "(a) Abundance: Prediction vs. Uncertainty",
  x_lab = "Predicted Abundance (Count)",
  y_lab = "Uncertainty Width",
  stats_result = correlation_results_list$Total_Abundance$mag
)
plot_list[["p_ab_dist"]] <- create_scatter_plot(
  data = sampled_data_list$Total_Abundance$dist,
  x_var = "Distance",
  y_var = "Uncertainty",
  title = "(b) Abundance: Distance vs. Uncertainty",
  x_lab = "Distance to Nearest Trap (m)",
  y_lab = "Uncertainty Width",
  stats_result = correlation_results_list$Total_Abundance$dist
)
plot_list[["p_ab_env"]] <- create_scatter_plot(
  data = sampled_data_list$Total_Abundance$env,
  x_var = "Environment",
  y_var = "Uncertainty",
  title = "(c) Abundance: Top Predictor vs. Uncertainty",
  x_lab = "Annual Mean Temperature (°C)",
  y_lab = "Uncertainty Width",
  stats_result = correlation_results_list$Total_Abundance$env
)

#-- Onset Week Plots --
plot_list[["p_on_mag"]] <- create_scatter_plot(
  data = sampled_data_list$Onset_Week$mag,
  x_var = "Prediction",
  y_var = "Uncertainty",
  title = "(d) Onset: Prediction vs. Uncertainty",
  x_lab = "Predicted Onset (Week of Year)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Onset_Week$mag
)
plot_list[["p_on_dist"]] <- create_scatter_plot(
  data = sampled_data_list$Onset_Week$dist,
  x_var = "Distance",
  y_var = "Uncertainty",
  title = "(e) Onset: Distance vs. Uncertainty",
  x_lab = "Distance to Nearest Trap (m)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Onset_Week$dist
)
plot_list[["p_on_env"]] <- create_scatter_plot(
  data = sampled_data_list$Onset_Week$env,
  x_var = "Environment",
  y_var = "Uncertainty",
  title = "(f) Onset: Top Predictor vs. Uncertainty",
  x_lab = "Annual Mean Temperature (°C)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Onset_Week$env
)

#-- Peak Week Plots --
plot_list[["p_pk_mag"]] <- create_scatter_plot(
  data = sampled_data_list$Peak_Week$mag,
  x_var = "Prediction",
  y_var = "Uncertainty",
  title = "(g) Peak: Prediction vs. Uncertainty",
  x_lab = "Predicted Peak (Week of Year)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Peak_Week$mag
)
plot_list[["p_pk_dist"]] <- create_scatter_plot(
  data = sampled_data_list$Peak_Week$dist,
  x_var = "Distance",
  y_var = "Uncertainty",
  title = "(h) Peak: Distance vs. Uncertainty",
  x_lab = "Distance to Nearest Trap (m)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Peak_Week$dist
)
plot_list[["p_pk_env"]] <- create_scatter_plot(
  data = sampled_data_list$Peak_Week$env,
  x_var = "Environment",
  y_var = "Uncertainty",
  title = "(i) Peak: Top Predictor vs. Uncertainty",
  x_lab = "Mean Temp. of Coldest Quarter (°C)",
  y_lab = "Uncertainty Width (Weeks)",
  stats_result = correlation_results_list$Peak_Week$env
)


#---- 5.3. Combine and Save Final Figure ----
if (length(plot_list) == 9) {
  final_appendix_plot <- wrap_plots(plot_list, ncol = 3) +
    plot_annotation(
      title = "Supplementary Figure: Relationships with Prediction Uncertainty",
      theme = theme(plot.title = element_text(
        hjust = 0.5,
        size = 14,
        face = "bold"
      ))
    )
  
  # Define the output path
  output_plot_path <-
    file.path(dir_evaluation, "appendix_figure_uncertainty_scatter.png")
  
  # Save the plot
  ggsave(
    filename = output_plot_path,
    plot = final_appendix_plot,
    width = 12,
    height = 10,
    dpi = 300
  )
  
  print(paste(
    "--- Appendix scatter plot figure saved to:",
    output_plot_path,
    "---"
  ))
  
} else {
  print("Not all plots were generated, skipping final figure creation.")
}

print("\n--- All statistical analyses complete. ---")